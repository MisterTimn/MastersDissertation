\chapter{Uitvoering \& resultaten}
\section{Gebruikte technologie\"en}
Alle programmatie wordt uitgevoerd in Python, een dynamische \textit{high-level} programmeertaal. Python is ontwikkeld met het oog op leesbare en kernachtige code. Het is een van de meest gebruikte talen voor het uitvoeren van wetenschappelijke experimenten, mede dankzij de vele krachtige bibliotheken die beschikbaar zijn. In dit onderzoek worden de volgende Python-bibliotheken gebruikt:

\begin{itemize}
	\item NumPy: voegt ondersteuning toe voor grote, multi-dimensionale arrays en matrices samen met een groot assortiment aan wiskundige functies om deze arrays effici\"ent te  manipuleren. Deze bibliotheek is een onderdeel van de SciPy-stack (Scientific Python).
	\item Theano \cite{theano}:  een bibliotheek die toelaat wiskundige expressies te defini\"eren, optimaliseren en evalueren. De twee belangrijkste troeven van Theano zijn de dynamische generatie van c-code en het transparante gebruik van GPU-acceleratie. Expressies worden symbolisch omgezet en gecompileerd voor een snelle en effici\"ente uitvoering. Ook worden ze geoptimaliseerd  voor gebruik van de GPU.  Hiernaast biedt de bibliotheek ook heel wat functies voor machine learning. 
	\item Lasagne \cite{lasagne}: een lightweight bibliotheek voor het bouwen en trainen van neurale netwerken. Het biedt verschillende veelgebruikte kosten-, regularisatie-, activatie- en leerfuncties aan alsook vele soorten \textit{layers}. Zo gebruikt dit werk de \textit{DenseLayer} voor volledig verbonden lagen en de \textit{Conv2DLayer} voor de tweedimensionale convolutie. Deze bibliotheek bouwt verder op functionaliteit van Theano waardoor neurale netwerken gebouwd met Lasagne ook gebruik kunnen maken van GPU-acceleratie.
	\item Scikit-learn: deze bibliotheek biedt heel wat machine learning functionaliteit aan maar hiervan wordt in dit onderzoek geen gebruik gemaakt. Het pakket binnen scikit-learn dat wel gebruikt wordt, is \textit{metrics}. Deze wordt gebruikt voor de evaluatie van het model. Vanuit de voorspelde en ware labels kunnen we via diverse functies de kwaliteit van de classificatie beschouwen. Dit pakket wordt voornamelijk gebruikt voor het berekenen van de precision en recall, en het opstellen van de confusion matrix. Deze termen worden verklaard in Sectie \ref{sec:pr-conf}.
	\item Scikit-image: is een verzameling beeldverwerkingsalgoritmes. Deze bibliotheek wordt gebruikt voor de data-augmentatie.
	
\end{itemize}
\section{ChaLearn dataset}
De gebruikte dataset is die van de ``ChaLearn Looking at People Challenge 2014'' zoals beschreven in \cite{escalera_chalearn_2014}. Uit deze set wordt de derde track gebruikt: ``gesture recognition''. Deze bevat meer dan 14000 gebaren uit een vocabularium van twintig Italiaanse gebaren. Merk op dat het hier niet gaat om een gebarentaal maar om afzonderlijke gebaren uit de Italiaanse cultuur. De verschillende gebaren en hun benamingen zijn te zien in Figuur \ref{fig:gebaren}.
\begin{figure}
	\centering
	%	\def\svgscale{0.85}
	\def\svgwidth{\columnwidth}
	\input{figuren/gebaren.pdf_tex}
	\caption{De Italiaanse gebaren gebruikt in de ``ChaLearn Looking At People Challenge 2014, Track 3: gesture spotting''}
	\label{fig:gebaren}
\end{figure}
\npar De gebaren worden uitgevoerd door 27 gebruikers tegen verschillende achtergronden. Er is variatie op vlak van kleding, lichaamsbouw, belichting en gebaaruitvoering. De beelden zijn opgenomen met behulp van een Kinect camera waardoor er vier datastromen zijn: RGB-beeld, dieptebeeld, gebruikersindex en skeletinformatie (Figuur \ref{fig:chalearn-data}).
\begin{figure}
	\centering
	%	\def\svgscale{0.85}
	\def\svgwidth{\columnwidth}
	\input{figuren/chalearn-data.pdf_tex}
	\caption{De vier datastromen beschikbaar in de ``ChaLearn Looking At People Challenge 2014, Track 3: gesture spotting'' dataset}
	\label{fig:chalearn-data}
\end{figure}
\npar Deze dataset werd ook gebruikt in \cite{lionel} waar deze een aantal voorverwerkingsstappen onderging. Deze voorverwerkte dataset is ter beschikking gesteld van dit onderzoek. De voorverwerking probeert de dataset te optimaliseren voor gebarenherkenning. De dataset bestaat uit tienduizend ge\"isoleerde gebaren samen met hun correcte klasselabel. Er worden 32 frames geselecteerd rond het midden van elk gebaar. Vervolgens worden er vier nieuwe datastromen gecre\"eerd door het uitsnijden van de linker en rechterhand uit zowel diepte- als RGB-beeld. Ook wordt het bovenlichaam ge\"isoleerd om een deel van de achtergrond weg te werken. In totaal zijn er zo zes datastromen beschikbaar. Elk beeld, origineel 640x480 pixels groot, wordt gedownscaled en gecropt tot een grootte van 64x64 pixels. 

\npar In dit onderzoek wordt de dataset opgedeeld in 60\% training-, 20\% validatie- en 20\% testset. Deze opdeling is sequentieel gebeurd: het eerste deel voor training, het tweede deel voor validatie en het laatste voor test. De dataset is gesorteerd per gebruiker waardoor er andere gebruikers voorkomen in de gesplitste datasets.


\section{Onderzoeksopzet}
\begin{figure}[t]
	\centering
	\input{figuren/schema-opzet.pdf_tex}
	\caption{Schema van het onderzoeksopzet. Het omkadere gedeelte is de eerste fase met het opstellen van het basismodel. Het onderste gedeelte wordt voor elk experiment uitgevoerd. $G_i$ staat voor voorbeelden van het gebaar met label $i$, $N$ voor het aantal samples dat gebruikt wordt voor hertraining.}
\end{figure}
De experimenten worden uitgevoerd op computers van het Reservoir Lab van de vakgroep Elektronica- en Informatiesystemen (ELIS) van de Universiteit Gent. De gebruikte computers hebben een hexacore processor (Intel Core i7-3930K) met kloksnelheid van 3.2 GHz en een NVIDIA Tesla K40c grafische kaart.

\npar In een eerste fase moet er een convolutioneel neuraal netwerk worden opgezet dat een aanvaardbare nauwkeurigheid behaalt op de gebruikte dataset. Dit model wordt besproken in Sectie \ref{sec:basismodel}. De nauwkeurigheden van dit predictief model, getraind op alle klassen met alle voorbeelden, wordt vervolgens gebruikt als vergelijkingspunt of \textit{baseline} voor de one-shot learning experimenten.

\npar In de volgende stap zal een model, qua architectuur en hyperparameters gelijkend op het basismodel, getraind worden op een deelverzameling van de gebaren. Na deze pre-training kan het model een gebaar bijgeleerd worden en wordt er ge\"experimenteerd met het aantal verschillende samples van het nieuwe gebaar, het aantal lagen dat hertraind worden en met het gebruik van data-augmentatie. De bespreking van deze experimenten gebeurt in Sectie \ref{sec:experimenten}.

\section{Ontwerp en optimalisatie van het basismodel}\label{sec:basismodel}
Alle keuzes omtrent hyperparameters en architectuur zijn experimenteel, op basis van gelijkaardige onderzoeken en naar advies van de begeleiding bepaald. Er zijn vele mogelijke combinaties qua hyperparameters en het is zeer tijdrovend om hierin de meest optimale keuze te maken. Dit is ook niet de essentie van dit onderzoek. Er dient een voldoende goed model opgesteld te worden om vergelijkingen te maken tussen het leren van alle gebaren (basismodel) en het bijleren van een gebaar. 
\begin{figure}[t]
	\centering
	%	\def\svgscale{0.85}
	\def\svgwidth{0.5\columnwidth}
	\input{figuren/dataset-input.pdf_tex}
	\caption{De 12 frames gebruikt voor de invoer van het CNN. De frames hebben een resolutie van 64x64 pixels.}
	\label{fig:dataset-input}
\end{figure}
\subsection{Invoer}
Uit het beeld van elk gebaar worden 4 frames gesampled per datastroom. Er is gekozen om niet van alle input gebruik te maken om een snellere trainingstijd te bekomen zodat er meer experimenten kunnen worden uitgevoerd. In een latere fase of bij verder onderzoek kan het model steeds uitgebreid worden om meer gebruik te maken van spatio-temporele data.
\npar Er wordt enkel gebruik gemaakt van het dieptebeeld, volgens \cite{lionel} en \cite{wu_deep_2014} ligt hierin de nuttigste informatie voor een CNN. Het gebruik van RGB-beeld in combinatie met grijswaardenbeeld voegt meestal weinig toe. Hierin kan dus ook weer rekentijd worden bespaard.

\npar Per voorbeeld zijn er 12 beelden zoals weergegeven in Figuur \ref{fig:dataset-input}. De input van de invoerlaag heeft dus een dimensie van 12x64x64. Merk op dat de beelden van de handen en het volledige bovenlichaam in hetzelfde CNN worden verwerkt. Alle uitgevoerde experimenten hanteren deze invoerdimensie.

\subsection{Architectuur}
\begin{figure}[t]
	\centering
	%	\def\svgscale{0.85}
	\def\svgwidth{\columnwidth}
	\input{figuren/First-model.pdf_tex}
	\caption{Het basismodel bestaande uit een drielagig CNN voor feature-extractie en een drielagig ANN (met softmax uitvoerlaag) voor classificatie}
	\label{fig:model-1}
\end{figure}
Het opgestelde basismodel is weergegeven in Figuur \ref{fig:model-1}
Het CNN bestaat uit drie convolutionele en max-pooling lagen. Alle max-pooling gebeurt met vensters van 2x2 zodat het beeld telkens gehalveerd wordt in grootte. De eerste convolutionele laag bevat 8 5x5 filters, de tweede 16 5x5 filters en de laatste 32 4x4 filters.
\npar De output van dit CNN wordt gebruikt als featurevector in een ANN voor classificatie. Het ANN bevat ook drie lagen, de twee verborgen lagen hebben respectievelijk 800 en 100 knopen. Alle verborgen knopen zijn ReLU's en aan de uitgangslaag wordt een softmax gebruikt met 20 units voor de classificatie van de verschillende gebaren.
\begin{table}
	\centering
	%	\vspace{5pt}
	\renewcommand{\arraystretch}{0.8}% 
	\begin{tabular}{ l l }
		\hline
		\textit{Hyperparameter} & \textit{Waarde} \\
		\hline
		\hline
		\textbf{Filters CNN:} & \\
		\quad Laag 1 & 8x(5x5) \\
		\quad Laag 2 & 16x(5x5) \\
		\quad Laag 2 & 32x(4x4) \\
		
		\textbf{Verborgen units ANN:} &\\
		\quad Laag 1 & 800\\
		\quad Laag 2 & 100 \\
		\hline
		Max-pooling vensters & 2x2\\
		Learning rate & $10^{-4}$\\
		Batch grootte & 32\\
		Dropout kans & 0.5\\
		Nesterov momentum & 0.9\\
		\hline
		\textbf{Initialisatie:} & \\
		Gewichten CNN & Glorot initialisatie (uit uniforme verdeling $[-a,a]$)\\
		Bias CNN & 0 \\
		Gewichten ANN & Glorot initialisatie (uit uniforme verdeling $[-a,a]$)\\
		Bias ANN & 0 \\
		\hline
		\textbf{Data-augmentatie:} & \\
		Zoom & [83.33,120] \%, uniforme verdeling \\
		Rotatie & [-2,2]$^{\circ}$, uniforme verdeling\\
		2D translatie & [-2,2] pixels, uniforme verdeling
		
	\end{tabular}	
	\caption{Hyperparameters van het basismodel}\label{tab:hyperparam}
\end{table}
\npar Een samenvatting van alle hyperparameters en gekozen architectuur is te vinden in Tabel \ref{tab:hyperparam}. Voor de regularisatie wordt er gebruik gemaakt van dropout. De gewichten worden ge\"initialiseerd met Glorot gewichten gesampled uit een uniforme verdeling. Deze gewichtsinitialisatie beschreven in \cite{glorot-1} is ontwikkeld voor deep learning methodes en de standaard initialisatiemethode van het Lasagne framework. Het zorgt ervoor dat de aangelegde invoer zich kan propageren tot diep in het netwerk. Zonder goede intitialisatie van de gewichten is er een risico dat het signaal te fel afzwakt waardoor de laatste lagen geen input krijgen.
\npar Er wordt ook aan data-augmentatie gedaan om de prestatie van het predictief model te verbeteren. De parameters van deze augmentatie staan beschreven in Tabel \ref{tab:hyperparam}. Deze parameters bleken later nogal conservatief gekozen, in Sectie \ref{sec:softmax19x1} wordt hierover uitgebreid.
%De gebruikte data-augmentatie bleek bij nader inzien geen zo'n grote impact te hebben door conservatief gekozen parameters zoals weergegeven onderaan Tabel \ref{tab:hyperparam}. De parameters voor translatie en rotatie zijn eigenlijk te klein en voegen weinig variatie toe aan de beelden. In Sectie \ref{sec:model-19x1} wordt hierover verder uitgebreid.
\subsection{Training}
\npar Mini-batch gradient descent aangevuld met Nesterov Augmented Momentum worden gebruikt als optimalisatie-algoritme. Alle training wordt uitgevoerd op de GPU waardoor we de CPU parallel kunnen gebruiken om de voorbeelden aan te voeren. Dit verloopt als volgt:
\begin{itemize}
	\item een werk-proces selecteert 32 willekeurig gekozen klasselabels
	\item per gekozen klasselabel wordt een random voorbeeld van die klasse gekozen uit de trainingset
	\item elk voorbeeld wordt geaugmenteerd met behulp van een transformatiematrix
	\item de voorbeelden worden in het gedeelde geheugen geplaatst en opgehaald voor training van het model
	\item tijdens de training op deze mini-batch wordt de volgende klaargezet
\end{itemize}
Na 250 iteraties, die we verder een \textit{epoch} zullen noemen, wordt het model ge\"evalueerd met de validatieset. Het minimum van de validatiefout wordt bijgehouden en telkens we een lagere waarde bereiken worden de modelparameters opgeslaan. De training stopt wanneer er na 25 epochs geen verbetering meer te zien is in de validatiefout.

\subsection{Baseline resultaten met behulp van precision, recall en confusion matrix}\label{sec:pr-conf}
Om de baseline op te stellen wordt de volledige trainingset gebruikt om de 20 gebaren van de dataset te leren classificeren. Het voorgestelde model convergeert na ongeveer 250 epochs en behaalt een totale nauwkeurigheid van 81,20 \%.

\begin{figure}[!t]
	\centering
	%	\def\svgscale{0.85}
	\def\svgwidth{0.7\columnwidth}
	\input{figuren/prec+recall.pdf_tex}
	\caption{Visualisatie van de betekenis van precision en recall. Links zijn alle relevante elementen te zien die zouden moeten geselecteerd worden. Het omcirkelde gedeelte zijn de effectief geselecteerde elementen of de voorspellingen van het model}
	\label{fig:prec+recall}
\end{figure}
\npar Om een evaluatie te maken van de prestatie van het model wordt gebruik gemaakt van de precision en recall scores. Figuur \ref{fig:prec+recall} geeft een schematische weergave van de betekenis van deze twee termen. Het model in dit schema krijgt de taak om alle grijze bollen te selecteren. De grijze bollen noemen we de \textit{relevante elementen}. De relevante elementen binnen de selectie zijn de echt positieven of \textit{True Positives} (TP). De niet-relevante elementen binnen de selectie noemen we de vals positieven of \textit{False Positives} (FP). De positieve voorspellende waarde of precision wordt als volgt beschreven:
\begin{equation}
Precision = \frac{TP}{TP+FP}
\end{equation}
Alle relevante elementen die niet zijn geselecteerd worden de vals negatieven of \textit{False Negatives} (FN) genoemd. De sensitiviteit of recall wordt als volgt gedefinieerd:
\begin{equation}
Recall = \frac{TP}{TP+FN}
\end{equation}
Precision geeft aan hoeveel van de geselecteerde elementen relevant zijn terwijl recall aangeeft hoeveel van de relevante elementen werden geselecteerd. Een goed classificatiemodel heeft zowel een hoge precision als een hoge recall.

\npar Om naast de precision en recall waardes een globaal beeld te krijgen van de prestatie van een model wordt ook gebruik gemaakt van de \textit{confusion matrix}. In Figuur \ref{fig:conf-allegebaren} is de genormaliseerde confusion matrix van het basismodel te zien. Op de verticale as staan de ware labels en op de horizontale as de voorspelling van het model. Hierdoor staan alle TP's op de diagonaal van de matrix. Hoe hoger de waardes op de diagonaal, hoe beter het model presteert. Op een confusion matrix is het heel gemakkelijk om te zien welke klassen het vaakst worden verward.

\npar In het geval van het basismodel (Figuur \ref{fig:conf-allegebaren}) liggen de waarden op de diagonaal relatief hoog. In het algemeen ligt de verwarring van het model dus laag. Klassen waarmee moet opgelet worden omdat die vaker worden verward zijn bijvoorbeeld klasse 3 en 9 ($\sim$15 \% van klasse 3 en $\sim$20 \% van klasse 9). Dit zijn twee gebaren waarbij de beweging van de hand rond het hoofd gebeurt (zie Figuur \ref{fig:gebaren}). Ook klasse 13 en 14 worden ondanks hun relatief hoge ware voorspellingswaarde ook vaak verward ($\sim$7 \% van klasse 13 en $\sim$13 \% van klasse 14). De beweging van de dominante hand bij deze gebaren is ietwat gelijkaardig en blijft steeds naast het lichaam.

\begin{figure}
	\centering
	\def\svgwidth{0.8\columnwidth}
	\input{figuren/conf_alle_klassen.pdf_tex}
	\caption{Genormaliseerde confusion matrix van baseline voorspellingen van het basismodel, getraind op alle voorbeelden van alle gebaren. De waarde van een punt in de matrix is de fractie van het voorbeeld met ware label y dat voorspeld wordt als label x. Op de diagonaal zijn bijgevolg alle True Positives te zijn.}
	\label{fig:conf-allegebaren}
	
	\vspace{1cm}
	\begin{tabular}{l l}
		\begin{tabular}{l l l}
			\hline
			\textbf{Label} & \textbf{Precision} &
			\textbf{Recall}\\
			\hline
			0 & 84,71 \% & 77,42 \% \\
			1 & 71,17 \% & 77,45 \% \\
			2 & 81,82 \% & 80,00 \% \\
			3 & 62,04 \% & 67,00 \% \\
			4 & 92,15 \% & 93,07 \% \\
			5 & 87,04 \% & 90,38 \% \\
			6 & 84,71 \% & 77,42 \% \\
			7 & 74,59 \% & 85,05 \% \\
			8 & 93,46 \% & 93,46 \% \\
			9 & 58,54 \% & 49,48 \% \\
			\hline
		\end{tabular} & 
		\begin{tabular}{l l l}
			\hline
			\textbf{Label} & \textbf{Precision} &
			\textbf{Recall}\\
			\hline
			10 & 77,27 \% & 67,33 \% \\
			11 & 84,33 \% & 69,31 \% \\
			12 & 91,57 \% & 92,55 \% \\
			13 & 80,39 \% & 79,61 \% \\
			14 & 56,41 \% & 74,16 \% \\
			\textbf{15} & \textbf{96,88} \% & \textbf{94,90} \% \\
			16 & 91,35 \% & 92,23 \% \\
			17 & 75,27 \% & 72,92 \% \\
			18 & 90,69 \% & 83,87 \% \\
			19 & 91,51 \% & 93,27 \% \\
			\hline
		\end{tabular}	
	\end{tabular}
	\captionof{table}{Precision en recall voor de voorspellingen van het basismodel getraind op alle voorbeelden van alle gebaren.}
	\label{tab:pr-alle-klassen}
\end{figure}

\npar In Tabel \ref{tab:pr-alle-klassen} zijn alle precision en recall scores van het basismodel opgelijst. Deze scores zullen gebruikt worden als baseline voor de experimenten met het bijleren en one-shotten van een gebaar. Het zijn de waardes die we nastreven bij het hertrainen.



\section{Een gebaar bijleren}\label{sec:experimenten}

De architectuur en parameters van het basismodel worden overgenomen voor de experimenten rond het bijleren van een gebaar. Voor een eerste test wordt een model identiek aan het basismodel voorgetraind op negentien gebaren en een nieuw gebaar bijgeleerd. Dit is het \textit{softmax20} model en wordt besproken in Sectie \ref{sec:softmax20}.
\npar Om een dynamisch uitbreidbaar systeem te bekomen wordt de architectuur van het basismodel aangepast, zodat er per nieuw gebaar een nieuw te trainen unit kan toegevoegd worden. Hier zijn er twee experimenten rond opgebouwd: het bijleren van \'e\'en gebaar in het \textit{softmax19+1} model (Sectie \ref{sec:softmax19x1}) en het bijleren van twee gebaren na elkaar met het \textit{softmax18+1+1} model (Sectie \ref{sec:softmax18x2})

\subsection{Softmax20 model}\label{sec:softmax20}

De eerste experimenten rond het bijleren van een gebaar worden uitgevoerd op een model volledig gelijk aan het basismodel (zoals afgebeeld in Figuur \ref{fig:model-1}). Eerst wordt het model getraind met een trainingset van negentien gebaren. Als het model geconvergeerd en genoeg geregulariseerd is, zou het een aantal algemene features van een nieuw gebaar moeten herkennen.

\npar Er wordt met negentien van de twintig gebaren getraind om zo veel mogelijk verschillende features te kunnen leren aan het model. Hoe meer verschillende gebaren er vooraf kunnen aangeleerd worden, hoe beter het model zou moeten presteren op de classificatie van een nieuw gebaar. Het zal verplicht worden om meer algemene features te detecteren en er zullen er ook meer worden aangeleerd. Omdat de gebruikte dataset eerder beperkt is wordt hij hier maximaal benut.

\npar De pretraining gebeurt op een softmax van twintig units, \'e\'en unit wordt dus niet gebruikt. Deze opstelling is niet bruikbaar om een dynamisch uitbreidbaar herkenningssysteem te maken, omdat ze ervan uit gaat dat er slechts \'e\'en gebaar zal worden toegevoegd. Eenmaal het model getraind is op het nieuwe gebaar zijn alle softmax units gebruikt. Het is wel een goede eerste test van het potenti\"eel van het model.

\npar Door het model te hertrainen met de trainset van negentien gebaren aangevuld met een aantal samples van het nieuwe gebaar leren we het model ook op deze klasse te activeren. Om de hyperparameters van het model te optimaliseren wordt het na elke epoch ge\"evalueerd met de volledige validatieset. Deze bevat alle beschikbare voorbeelden van het nieuwe gebaar zodat er kan gelet worden op overfitting van het model op het kleine aantal trainingsvoorbeelden.

\npar Een finale evaluatie wordt gemaakt met alle voorbeelden uit de testset. Uit de voorspelling op deze testset worden de precision en recall scores van de klasse berekend en ge\"evalueerd.

\begin{figure}
	\centering
	\includegraphics{naive-oneshot-lagen-vergelijking.pdf}
	\caption{Precision en recall voor de classificatie van gebaar 15 met het softmax20 model in functie van het aantal gebruikte samples voor bijleren. De streepjeslijnen geven de baseline weer van het model getrained op alle voorbeelden.}\label{fig:naive-model}
\end{figure}

\npar Eerst en vooral wordt het aantal samples gevari\"eerd. Het model wordt getraind met 200, 100, 50, 25, 10, 5, 4, 3, 2 voorbeelden en ten slotte wordt er 1 voorbeeld gebruikt voor een poging tot one-shot learning.
\npar Ook wordt het effect van het aantal hertrainde lagen onderzocht. Eerst wordt enkel de laatste laag, de softmax, hertraind. Alle andere parameters van het model blijven dus ongewijzigd. In een tweede experiment worden de softmax en de laatste verborgen laag, deze met 100 units, hertraind.

\npar In Figuur \ref{fig:naive-model} zijn de resultaten van deze experimenten met het \textit{softmax20} model te zien. Het bijgeleerde gebaar is het gebaar nummer 15: "non ce ne piu". Het basismodel getraind op alle voorbeelden behaalde een 96.88\% precision en 94.90\% recall score op dit gebaar, de hoogste scores van alle gebaren. Enerzijds zou dit gebaar dus gemakkelijk moeten aan te leren zijn aangezien het heel nauwkeurig voorspeld wordt. Anderzijds kan het model zich niet meer beroepen op de features geleerd uit dit gebaar aangezien ze niet in de pretraining is opgenomen.

\npar Het is opvallend dat de precision scores voor beide experimenten heel dicht liggen bij de baseline. Het model is dus redelijk zeker dat het om het nieuwe gebaar gaat als het dit gebaar herkent. Bij het hertrainen van de twee laatste lagen met twee voorbeelden gaat de precisie zelfs boven die van de baseline.

\npar De recall score volgt niet dezelfde lijn als die van de precision. Hier zien we duidelijk dat de recall bij gebruik van weinig samples heel laag ligt. De stijlste klimming bij het model waar enkel de softmax wordt hertraind zien we tot aan het gebruik van vijf samples. Bij het hertrainen van twee lagen loopt deze stijging door tot tien samples. Dit kan verklaard worden doordat er meer parameters geoptimaliseerd moeten worden bij het het hertrainen van de twee lagen. Meer parameters vragen om meer voorbeelden, bij gebruik van meer dan tien samples scoort dit model dan  ook beter.

\npar Omdat er twintig softmax units gebruikt worden voor het classificeren van negentien gebaren wordt er ten slotte nagegaan of het model tijdens de pretraining geen zogenaamde \textit{garbage class} traint. Dit is een klasse waarin het model voorbeelden indeelt die hij niet herkent. Bij wijze van test wordt het voorgetrainde model (zonder hertraining op het uitgesloten gebaar) ge\"evalueerd met de testset. Uit deze test blijkt dat 0\% van alle voorbeelden in deze klasse wordt ingedeeld, er is dus geen garbage class getraind. 
%\npar Het opzet van dit onderzoek is zo weinig mogelijk samples te gebruiken, voor verdere experimenten werd er dus gekozen om enkel de softmax te hertrainen van het nieuwe gebaar

\subsection{Softmax19+1 model}\label{sec:softmax19x1}
We willen naar een dynamisch uitbreidbaar systeem toewerken. Het vorige model gaat uit van slechts \'e\'en bij te leren gebaar en is hier dus niet bruikbaar voor. In de praktijk zullen we niet van tevoren weten hoeveel gebaren er zullen toegevoegd worden. Het aantal softmax eenheden moet variabel en uitbreidbaar zijn om meer dan het originele aantal gebaren te kunnen herkennen. Om aan deze uitbreidbaarheid te voldoen en om verder onderzoek te voeren wordt het \textit{Softmax19+1} model opgesteld, te zien in Figuur \ref{fig:19+1}.

\begin{figure}
	\centering
	\def\svgwidth{0.7\columnwidth}
	\input{figuren/softmax19+1.pdf_tex}
	\caption{Schematische weergave van het softmax19+1 model. De blauwe lagen zijn voorgetraind en worden niet gewijzigd. Er wordt \'e\'e unit voor het nieuwe gebaar toegevoegd (aangeduid in het geel) en zijn gewichten worden getraind. De uitvoer van deze twee parallelle lagen wordt samengebracht in een softmax met twintig units. Vandaar de benaming softmax19+1.}\label{fig:19+1}
\end{figure}

\npar Hier wordt eerst een model met negentien softmax units getraind voor de classificatie van negentien gebaren. Behalve het verschil in aantal softmax units is de architectuur volledig gelijk aan die van het basismodel. Daarna wordt het model uitgebreid met een extra unit voor de classificatie van het nieuwe gebaar. Het nieuwe neuron wordt volledig verbonden met de laatste dense layer van honderd units en enkel de gewichten van deze verbindingen worden getraind. Vervolgens wordt er een softmax activatie uitgevoerd op alle twintig units samen, zodat er twintig gebaren kunnen geclassificeerd worden.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{19x1-gebaar15.pdf}
	\caption{Precision en recall voor de classificatie van gebaar 15 met het softmax19+1 model in functie van het aantal gebruikte samples voor bijleren.}\label{fig:19x1-gebaar15}
	
		\vspace{0.5cm}
		\def\svgwidth{1.1\columnwidth}
		\input{figuren/19x1-oneshot-vgl.pdf_tex}
		\caption{Barplots per gebaar van de precision en recall van de baseline en na het hertrainen met respectievelijk \'e\'en en tien samples. }\label{fig:19x1-all}
\end{figure}

\npar Het leren gebeurt enkel op de gewichten van de unit van het nieuwe gebaar. Aan de verborgen laag van de negentien al geleerde gebaren wordt niet geraakt zodat het herkenningsvermogen op deze gebaren gelijk blijft. Dit zal ook een vereiste zijn van een uitbreidbaar herkenningssysteem, het bijleren van een nieuw gebaar mag geen negatief effect hebben op de huidige prestatie van het model.

\npar Met dit model kan er voor elk bijkomend gebaar een nieuwe unit worden toegevoegd en bijgevoegd worden aan de softmaxactivatie. Zo kan het herkenbaar lexicon  blijven groeien.

\subsubsection{Invloed van het aantal samples}

Het softmax19+1 model wordt getoetst tegen de prestatie van het softmax20 model. In Figuur \ref{fig:19x1-gebaar15} is de precision en recall van de classificatie van gebaar 15 te zien in functie van het aantal samples dat gebruikt wordt in de trainingset. Ook de prestatie van het softmax20 model bij hertrainen van enkel de softmax laag is geplot in streepjeslijnen. De waarden liggen niet zo heel ver uiteen. De precision van het softmax19+1 model ligt iets lager bij gebruik van minder dan tien samples. Wel ligt de recall score globaal hoger dan die van het softmax20 model. Bij het trainen op een voorbeeld is dit 25,51 \% tegenover 10,20\%. De recall curve volgt dezelfde stijle klim tot aan het gebruik van vijf samples, tot 73,47\% waarna het nog licht stijgt bij 25 samples en dan rond de 78\% blijft.

\subsubsection{Invloed van het bijgeleerde gebaar}

De prestatie van het softmax19+1 model volgt dus dezelfde trend als die van het softmax20 model. De resultaten hier weergegeven zijn allemaal na het bijleren van gebaar 15. Welk gebaar er bijgeleerd wordt heeft uiteraard ook een invloed op de prestatie van het model. Sommige gebaren hebben vele features gemeenschappelijk met andere gebaren, andere zijn eerder uniek en zullen moeilijk herkend worden.

\npar Om een beeld te scheppen van de invloed van het bij te leren gebaar werd voor elk gebaar eerst een model getraind exclusief dit gebaar, waarna het werd bijgeleerd met \'e\'en sample en met tien samples. Op Figuur \ref{fig:19x1-all} zijn de resultaten van dit experiment te zien. Bovenaan is de precision uitgeplot van alle gebaren, onderaan de recall.

\npar De recall score na bijleren met \'e\'en sample en met tien samples volgt dezelfde lijn als die van de baseline. Gebaren die een lagere recall score hebben na trainen op alle voorbeelden van alle gebaren scoren ook lager als we ze bijleren, zie bijvoorbeeld klasse 3 en 9. Hetzelfde geldt voor gebaren die hoog scoren. Zeker bij vergelijking van het gebruik van tien samples is dit opmerkelijk.

\npar De precision volgt ook dezelfde trend maar de verschillen zijn veel kleiner. De bevindingen uit het eerste experiment op gebaar 15 zijn dus door te trekken naar de andere gebaren.

\subsubsection{Invloed van data-augmentatie}
Ten slotte wordt ook nog een experiment opgezet om de invloed van data-augmentatie te onderzoeken. Tot voor dit experiment werd data-augmentatie toegepast met de parameters beschreven in Tabel \ref{tab:hyperparam}. Nieuwe testen worden opgezet die geen augmentatie gebruiken en hier is duidelijk dat de augmentatie weinig tot geen effect heeft. De gekozen parameters blijken erg conservatief en brengen te weinig variatie in de data. Er wordt geprobeerd om een meer drastische data-augmentatie toe te passen. Data-augmentatie verandert de echte voorbeelden, waardoor de dataset artificieel vergroot wordt. Hierdoor is er veel meer informatie ter beschikking en om deze te  beschrijven heeft het model meer parameters nodig.
\npar Dit is uitgetest met een model met het dubbele aantal filterbanken in de convolutielagen en twee maal 512 units in de verborgen lagen van het ANN. Na analyse blijkt het model te underfitten: het is nog niet complex genoeg om de geaugmenteerde data te beschrijven. Om deze opstelling te optimaliseren dient er opnieuw een iteratief proces van hyperparameteroptimalisatie aangevat te worden. Hier is niet verder op ingegaan, het is wel vrij zeker dat data-augmentatie een positief effect zal hebben aangezien het bij toepassingen zoals  \cite{cnn-krizhevsky} en \cite{cnn-karpathy} de prestaties verbetert. Bij one-shot learning en het bijleren uit weinig gebaren is het grootste probleem het tekort aan datavoorbeelden en dit is nu net wat data-augmentatie aanpakt. Deze techniek kan dus zeker verder onderzocht worden in toekomstig werk.

\subsection{Softmax18+1+1 model}\label{sec:softmax18x2}
Het is dus mogelijk om \'e\'en gebaar toe te voegen door het toevoegen van een nieuw neuron. Om aan te tonen dat we het model dynamisch kunnen blijven uitbreiden wordt analoog aan het principe van het softmax19+1 model een architectuur gemaakt dat twee gebaren na elkaar bijleert. Eerst wordt een model met achttien softmax units getraind. Na deze pretraining wordt er een unit voor het bij te leren gebaar toegevoegd en net zoals het vorige model worden de uitgangen van de achttien units en de nieuwe unit samengevoegd in een softmaxactivatie van negentien units.
\npar Het model leert een gebaar bij door de training van het nieuw toegevoegde unit en wordt daarna opnieuw uitgebreid met nog een extra unit voor het tweede gebaar. Ook deze unit wordt geconcateneerd zodat er uiteindelijk een softmaxlaag van twintig units is (18+1+1).

\npar Door op deze manier te werk te gaan is het theoretisch mogelijk om gebaren te blijven toevoegen. Na het toevoegen van een aantal gebaren kunnen de units effectief samengevoegd worden tot een laag waarna het proces opnieuw kan beginnen.

\npar In Figuur \ref{fig:18x2} zijn de resultaten te zien van het bijleren van gebaar 13 en gebaar 18. Eerst wordt gebaar 13 bijgeleerd, daarna gebaar 18, telkens met even veel voorbeelden. De recall score van beide gebaren ligt hoger dan wanneer ze elk afzonderlijk worden bijgeleerd in het softmax19+1 model. De precision ligt dan wel weer lager, vooral bij gebaar 13 dat eerst werd aangeleerd.

\npar Waarom de recall hoger ligt dan bij het softmax19x1 model valt moeilijk te verklaren. Het bijleren van een gebaar blijkt in al de experimenten erg afhankelijk van welk gebaar wordt bijgeleerd en uit welke gebaren wordt voorgeleerd. Om dit verder uit te zoeken zouden er meer experimenten met andere gebaren moeten worden uitgevoerd.

\npar Figuur \ref{fig:conf-18x2} geeft de genormaliseerde confusion matrix weer van het bijleren uit een voorbeeld. Hierop is te zien dat er een kleine verwarring is tussen de twee nieuw aangeleerde gebaren: 6\% van gebaar 18 wordt verward met 13 en omgekeerd 3\%. De grootste verwarring bij gebaar 18 is met gebaar 14: 31\%. In het baseline model is dit ook de grootste mate van verwarring bij gebaar 18 (6\%, te zien in Figuur \ref{fig:conf-allegebaren}).


\begin{figure}
	\centering
	\includegraphics[width=0.8\columnwidth]{18x2.pdf}
	\caption{Precision en recall na het bijleren van gebaar 13 en gebaar 18 in het \textit{softmax18+1+1} model. Ter vergelijking is het resultaat van het \textit{softmax19+1} model ook uitgetekend.}\label{fig:18x2}
	\vspace{1.5cm}
	\def\svgwidth{0.8\columnwidth}
	\input{figuren/conf-18x2.pdf_tex}
	\caption{Genormaliseerde confusion matrix van het \textit{softmax18+1+1} model na leren van gebaar 13 en gebaar 18 met een voorbeeld.}\label{fig:conf-18x2}
\end{figure}