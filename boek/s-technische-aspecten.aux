\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{machine_overview}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Technische aspecten}{8}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Machine Learning}{8}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Inleiding}{8}{subsection.2.1.1}}
\citation{krizhevsky2012imagenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Gesuperviseerde classificatie}{9}{subsection.2.1.2}}
\newlabel{eq:classifier}{{2.2}{10}{Gesuperviseerde classificatie}{equation.2.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Overfitting}{10}{subsection.2.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Schematische weergave van het opstellen van een predictief model met behulp van machine learning technieken \relax }}{11}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:alg-class-model}{{2.1}{11}{Schematische weergave van het opstellen van een predictief model met behulp van machine learning technieken \relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Plot van trainings- en validatiefout ter illustratie van overfitting en de early stopping techniek.\relax }}{11}{figure.caption.8}}
\newlabel{fig:overfitting}{{2.2}{11}{Plot van trainings- en validatiefout ter illustratie van overfitting en de early stopping techniek.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Artificieel neuraal netwerk}{12}{section.2.2}}
\newlabel{sec:ann}{{2.2}{12}{Artificieel neuraal netwerk}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Inleiding}{12}{subsection.2.2.1}}
\newlabel{eq:neuron}{{2.3}{12}{Inleiding}{equation.2.2.3}{}}
\newlabel{fig:neuron}{{2.3a}{13}{Artificieel neuron.\relax }{figure.caption.9}{}}
\newlabel{sub@fig:neuron}{{a}{13}{Artificieel neuron.\relax }{figure.caption.9}{}}
\newlabel{fig:ANN}{{2.3b}{13}{Artificieel neuraal netwerk\relax }{figure.caption.9}{}}
\newlabel{sub@fig:ANN}{{b}{13}{Artificieel neuraal netwerk\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Een ANN met een invoerlaag, twee verborgen lagen en een softmax uitvoerlaag samen met zijn bouwsteen, het artificieel neuron.\relax }}{13}{figure.caption.9}}
\newlabel{fig:test}{{2.3}{13}{Een ANN met een invoerlaag, twee verborgen lagen en een softmax uitvoerlaag samen met zijn bouwsteen, het artificieel neuron.\relax }{figure.caption.9}{}}
\citation{ReLU}
\citation{lionel}
\citation{wu_deep_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Weergave van de drie meest populaire activatiefuncties voor classificatie doeleinden \relax }}{14}{figure.caption.10}}
\newlabel{fig:activatie-fun}{{2.4}{14}{Weergave van de drie meest populaire activatiefuncties voor classificatie doeleinden \relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Training van een neuraal netwerk}{15}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Gradient descent}{16}{subsection.2.2.3}}
\newlabel{eq:grad-desc}{{2.8}{16}{Gradient descent}{equation.2.2.8}{}}
\newlabel{eq:mini-grad-desc}{{2.9}{16}{Gradient descent}{equation.2.2.9}{}}
\citation{botev_nesterovs_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Visualisatie van gradient descent algoritme in een tweedimensionale parameterruimte. De zwarte lijn geeft de verschillende iteratieve stappen van het algoritme weer. Door het volgen van de steilste helling wordt een lokaal minimum van de kostfunctie gevonden.\relax }}{17}{figure.caption.11}}
\newlabel{fig:gradient-descent}{{2.5}{17}{Visualisatie van gradient descent algoritme in een tweedimensionale parameterruimte. De zwarte lijn geeft de verschillende iteratieve stappen van het algoritme weer. Door het volgen van de steilste helling wordt een lokaal minimum van de kostfunctie gevonden.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Momentum-optimalisatie voor gradient descent}{17}{subsection.2.2.4}}
\citation{dropout}
\newlabel{fig:neuron}{{2.6a}{18}{ANN\relax }{figure.caption.12}{}}
\newlabel{sub@fig:neuron}{{a}{18}{ANN\relax }{figure.caption.12}{}}
\newlabel{fig:ANN}{{2.6b}{18}{ANN na toepassing dropout\relax }{figure.caption.12}{}}
\newlabel{sub@fig:ANN}{{b}{18}{ANN na toepassing dropout\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Links is een standaard ANN te zien met twee verborgen lagen, rechts is hetzelfde netwerk te zien na toepassing van dropout. De gekruiste units zijn de gedropte units.\relax }}{18}{figure.caption.12}}
\newlabel{fig:test}{{2.6}{18}{Links is een standaard ANN te zien met twee verborgen lagen, rechts is hetzelfde netwerk te zien na toepassing van dropout. De gekruiste units zijn de gedropte units.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Dropout}{18}{subsection.2.2.5}}
\citation{cnn-krizhevsky}
\citation{cnn-ji}
\citation{cnn-karpathy}
\citation{perronnin2010improving}
\citation{jhuang2007biologically}
\citation{hubel1968receptive}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Convolutioneel neuraal netwerk}{19}{section.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Lokale connectiviteit van receptieve velden. Voor elk overlappend deelgebied van de invoer is er een neuron verbonden. Alle gewichten van het lokale filter worden gedeeld.\relax }}{20}{figure.caption.13}}
\newlabel{fig:lokale-connectiviteit}{{2.7}{20}{Lokale connectiviteit van receptieve velden. Voor elk overlappend deelgebied van de invoer is er een neuron verbonden. Alle gewichten van het lokale filter worden gedeeld.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Tweedimensionale convolutie}{20}{subsection.2.3.1}}
\newlabel{eq:conv}{{2.12}{20}{Tweedimensionale convolutie}{equation.2.3.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Tweedimensionale convolutie met een 3x3 filter.\relax }}{21}{figure.caption.14}}
\newlabel{fig:conv}{{2.8}{21}{Tweedimensionale convolutie met een 3x3 filter.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Maximum pooling}{21}{subsection.2.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Maximum pooling: uit elk vak in de invoer afbeelding wordt het maximum bepaald en overgenomen in de bijhorende pixel in het uitvoerbeeld.\relax }}{22}{figure.caption.15}}
\newlabel{fig:max-pooling}{{2.9}{22}{Maximum pooling: uit elk vak in de invoer afbeelding wordt het maximum bepaald en overgenomen in de bijhorende pixel in het uitvoerbeeld.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Data-augmentatie}{22}{section.2.4}}
\newlabel{sec:data-augm}{{2.4}{22}{Data-augmentatie}{section.2.4}{}}
\@setckpt{s-technische-aspecten}{
\setcounter{page}{23}
\setcounter{equation}{14}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{9}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{lstnumber}{1}
\setcounter{LT@tables}{1}
\setcounter{LT@chunks}{1}
\setcounter{AM@survey}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{30}
\setcounter{lstlisting}{0}
\setcounter{section@level}{1}
}
