\chapter{Inleiding}
Om de communicatie tussen doven en horenden te verbeteren wordt er vandaag de dag onderzoek verricht naar een automatisch gebarentaalherkenningssysteem. Om om te gaan met de veranderlijkheid van een gebarentaal en de vele verschillende gebarentalen die er zijn, is het noodzakelijk dat we een herkenningssysteem kunnen uitbreiden.
\npar Deze systemen worden vaak ge\"implementeerd met behulp van deep learning technieken, zoals convolutionele neurale netwerken. Om deze modellen te optimaliseren voor een gegeven taak zijn er heel veel voorbeelden nodig. Wanneer we een dergelijk model een nieuw gebaar willen bijleren moet er dus een grote dataset worden verzameld om uit te leren. Ook zou het volledige model moeten hertraind worden, iets wat veel tijd kost.
\npar In dit onderzoek wordt nagegaan of we ook met weinig voorbeelden een model iets kunnen bijleren en of we hierbij slechts een gedeelte van het model kunnen hertrainen. Zo kan er een online platform worden opgesteld waarop via crowd-sourcing nieuwe gebarenvoorbeelden aan het model worden gegeven. Gebruikers kunnen dan via een webcam een gebaar uitvoeren, aangeven om welk gebaar het gaat en zo het model uitbreiden.
\npar In het ideale geval kan een systeem vanuit slechts \'e\'en gegeven voorbeeld een nieuw gebaar leren herkennen, zoals de mens dit ook kan. Dit speciaal geval van leren heet \textit{one-shot learning} en is het streefdoel van dit onderzoek.
\section{Gebarentaal}

Gebarentaal is in de eerste plaats een taal. Taal is een begrip dat moeilijk te defini\"eren valt en de meeste pogingen hiertoe beperken zich tot gesproken taal. Een definitie uit \cite{buyens_gebarentaaltolken_2003} die ook voor gebarentaal kan gebruikt worden is: 
\\``Een taal is een natuurlijk ontstaan menselijk communicatiemiddel waarmee je kan communiceren over alles wat je denkt, ziet, voelt en droomt. Een taal bestaat uit bouwstenen. Die bouwstenen worden volgens bepaalde regels samengevoegd tot grotere gehelen. Elke taal heeft eigen bouwstenen en regels''.

\npar Gesproken taal en gebarentaal verschillen in de manier waarop gecommuniceerd wordt: oraal-auditief tegenover gestueel-visueel. Door middel van hand-, hoofd- en armbewegingen wordt een woord ``uitgesproken'' en vervolgens visueel waargenomen.

\npar Een gebarentaal onstaat, net zoals een gesproken taal, spontaan en natuurlijk door contact tussen mensen. Net door deze spontane ontwikkeling is er geen universele gebarentaal. Evenals we verschillende gesproken talen en dialecten kennen per land of regio zijn er ook verschillende gebarentalen \cite{VGT-standard}. In Nederland is er bijvoorbeeld de Nederlandse Gebarentaal (NGT) en in Belgi\"e de Vlaamse Gebarentaal (VGT) en de Waalse Gebarentaal (la Langue des Signes de Belgique Francophone, LSFB). VGT verschilt dan weer van provincie tot provincie, met de grootste verschillen tussen West-Vlaanderen en Limburg, de twee verst uiteenliggende regio's.

\npar Een gebarentaal heeft een eigen grammatica en lexicon. Het lexicon of de gebarenschat is de verzameling van alle woorden of gebaren in de taal. De lokale gebarenschat moet volledig onafhankelijk van de lokale woordenschat worden beschouwd.
\\Bepaalde woorden uit de ene taal kunnen niet eenduidig vertaald worden in een andere taal. Het woord ``gezelligheid'' kent bijvoorbeeld geen Engelse vertaling en voor het Duitse ``fingerspitzengef\"uhl'' hebben we in de Nederlandse taal ook geen alternatief.
\\Tussen een gebarentaal en een gesproken taal geldt dezelfde verhouding. Er is niet altijd een \'e\'en-op-\'e\'en relatie tussen een woord en een gebaar.

\npar Communicatie tussen doven en horenden is vaak een struikelblok. Sommige doven kunnen liplezen en zo opmaken wat een spreker wil vertellen. Voorwaarde hierbij is dat de spreker goed moet articuleren en natuurlijk niet te snel spreekt.
\\ Er kan ook altijd schriftelijk gecommunciceerd worden, maar dit is een erg trage en onpersoonlijke vorm van communicatie. Ook is de bedrevenheid van een dove persoon in het schrijven van een gesproken taal vaak lager dan die van een horende.
\\ Doven kunnen zich ook beroepen op een tolk. Dit kan een vriend zijn die horende is en gebarentaal kent of een beroepstolk. In Vlaanderen kunnen doven terecht bij het Vlaams Communicatie Assistentie Bureau voor Doven (CAB) om een tolk in te huren \cite{tolkuren}. De Vlaamse overheid betaalt een aantal tolkuren terug. Onder andere achttien tolkuren voor priv\'edoeleinden, achttien voor sollicitaties en een situatie-afhankelijk aantal tolkuren voor arbeid en beroepsopleiding.
 
\section{Automatische gebarentaalherkenning}
Er is dus een communicatieprobleem tussen doven en horenden, omdat ze niet dezelfde taal spreken. Er zijn ook vele verschillende gebarentalen en dialecten waardoor er tussen doven onderling ook niet altijd vlot gecommuniceerd wordt.
Door het gebruik van hedendaagse technologie moet het mogelijk zijn hierin te helpen en een automatisch herkenningssysteem uit te werken waarmee gebaren in real-time kunnen vertaald worden.

\npar Het herkennen van objecten of gebaren is iets waar de mens niet bij stilstaat. Een pasgeboren kind begint vanaf het openen van de ogen zijn waarneming en herkenningsvermogen te trainen. Terwijl we leren, organiseren we vormen, objecten en categori\"en in nuttige taxonomi\"en en linken deze dan later naar onze taal \cite{oneshot-object-cat}. Eenmaal de leeftijd van zes jaar bereikt is, kan een kind bijvoorbeeld 104 objectcategorie\"en onderscheiden zonder hierbij stil te staan.

\npar Als mens kunnen we gebaren makkelijk differenti\"eren door registratie van armbewegingen, mimiek, houding van de handen en de manier waarop vingers gestrekt of geplooid worden. De neurologische fenomenen die deze vaardigheden kunnen verklaren worden nog steeds onderzocht. 

\npar Een machine of computer kan zien via het gebruik van een camera. Een beeld wordt voorgesteld door een matrix met pixelwaarden die de lichtintensiteit op dat bepaalde punt weergeeft. Traditioneel zijn er grijswaarden- en kleurbeelden maar tegenwoordig wordt ook vaak gebruikt gemaakt van 3D-cameratechnologie\"en, zoals de Microsoft Kinect \cite{kuhn2011kinect}, zodat er een aanvullend dieptebeeld is. Deze beelden gelden dan als de visuele data voor het systeem, daarna moeten specifieke technologi\"en worden ingezet om nuttige informatie uit deze data te halen.

\npar Een automatisch herkenningssysteem zal moeten leren omgaan met de grote variabiliteit van de invoer. De gebaren die het moet herkennen zullen uitgevoerd worden door mensen van verschillende grootte en lichaamsbouw. De vlotheid van het maken van gebaren tussen ervaren en beginnende gebarentaligen zal sterk verschillen en de persoon zal niet altijd mooi recht in het midden van het beeld staan of even ver van de camera. Ook links- en rechtshandigheid heeft een invloed op de gebaren evenals de expressiviteit van de spreker.
\\ De aanwezigheid van andere mensen of veel beweging in de achtergrond bemoeilijkt ook het herkennen van gebaren. Daarenboven moet ook nog rekening gehouden worden met de lokale belichting. De spreker kan onderbelicht of overbelicht zijn waardoor bepaalde contouren moeilijker te detecteren vallen.

\npar Een compleet gebarentaalherkenningssysteem zal moeten voorzien in gebarensegmentatie, gebarenherkenning en grammaticale samenstelling van gebaren.

\subsection{Gebarensegmentatie}
\npar Wanneer we een persoon die gebarentaal spreekt registreren met een camera krijgen we een continue stroom aan informatie. In een bepaalde tijdspanne kan een persoon een of meerdere gebaren uitvoeren en het is onbekend waneer een gebaar begint of eindigt. De segmentatie van deze gebaren is dus een eerste uitdaging voor een herkenningssysteem. Volgens \cite{hmdb-manual-segm} is er minder belangstelling naar deze ``continue'' gebaarherkenningssystemen omdat vaak wordt uitgegaan van vooraf gesegmenteerde beelden.
\npar  \cite{movement-epenthesis} bespreekt de bewegingsepenthesis. Tussen elk gebaar zit er een beweging die de overgang vormt tussen twee gebaren. Armen en handen gaan van eindpositie van het eerste gebaar naar beginpositie van het volgende. Deze beweging moet gedetecteerd en gefilterd worden willen we een foutloze segmentatie krijgen.

\subsection{Gebarenherkenning}
Eenmaal we weten wanneer een gebaar begint en eindigt kunnen we het identificeren. Uit de verzamelde visuele data wordt nuttige informatie ge\"extraheerd waarmee het model kan beslissen over welk gebaar het gaat. Het beeld wordt omgezet in een beeldrepresentatie, bestaande uit een of meerdere featurevectoren. Deze representatie wordt vervolgens gebruikt door een classificatiemethode die het een klasselabel geeft.

\npar \cite{gesture-FNN-HMM} stelt een gebaarherkenningssyteem voor die zich focust op de handen. Uit het dieptebeeld van een Kinectcamera wordt de hand gesegmenteerd via thresholding. Drie features worden vervolgens bijgehouden en gebruikt: de verandering van de handvorm, de beweging van de hand in het tweedimensionaal vlak en de beweging van de hand in de diepte (z-as).
\\Er wordt gebruik gemaakt van twee classificatie methodes: Hidden Markov Modellen (HMM) en Fuzzy Neurale Netwerken (FNN). HMM is een classificatietechniek die rekening houdt met het tijdsaspect. FNN is een combinatie van fuzzy (vage) theorie en artifici\"ele neurale netwerken.

\subsection{Grammaticale samenstelling}
Wanneer alle gebaren uit een continue stroom herkend worden, moeten we deze bouwstenen samenstellen tot een boodschap. Er moet rekening gehouden worden met grammaticale regels om zinnen en deelzinnen te vormen. Ook zijn er vele samengestelde woorden en specifieke gebarenpatronen om bepaalde termen weer te geven. Dit onderdeel zal dus op een hoger niveau werken en via toepassing van taalspecifieke regels de boodschap extraheren.
%Camera
%Features
%
%Gebaarsegmentatie
%Waar begint een gebaar en waar eindigt het
%Gebaarherkenning
%Welk gebaar en wat betekent het
%Boodschap ontleden --> gebaren samenstellen, grammatica, (bv. letterwoorden, kleur)

\section{One-shot learning}

\subsection{Uitbreidbaarheid herkenningssysteem}
Een taal is voortdurend in verandering.
Het lexicon van een gebarentaal groeit mee met de tijd. Gloednieuwe termen of zaken die voordien geen beschrijving kenden in een gebarentaal worden toegevoegd. Hogescholen en universiteiten gebruikten lange tijd geen gebarentaal waardoor er weinig wetenschappelijke termen opgenomen zijn in de gebarenschat. Gelukkig komen er vandaag steeds meer wetenschappelijke gebaren bij.

\npar Een automatische herkenningssysteem zal moeten leren omgaan met dit groeiende lexicon. Een strategie kan zijn om na verloop van tijd (vanaf een bepaald aantal nieuwe gebaren) het systeem te hertrainen met voorbeelden van de oude gebaren en de nieuwe gebaren. Hierbij wordt er dus vanaf nul gestart en een nieuw model opgebouwd.

\npar Een eerste probleem hierbij is het verzamelen van de data. Deep learning methodieken hebben een complexe structuur en erg veel parameters. Om een grote hoeveelheid parameters te optimaliseren voor een taak heb je een grote hoeveelheid data nodig om uit te leren. Als we dus een nieuw gebaar willen bijleren aan een herkenningssysteem hebben we vele voorbeelden nodig van dit ene gebaar, liefst tegen verschillende achtergronden, uitgevoerd door verschillende personen en in verschillende lichtomstandigheden.
\\ Het maken van dergelijke datasets is een erg kostelijke en tijdrovende opdracht.

\npar Het model vanaf nul terug hertrainen vraagt veel tijd en rekenvermogen. Alle vooraf opgedane kennis wordt gewist dus alle tijd en moeite die eerder ge\"investeerd werd is voor niets. Het systeem zal ook minstens evenveel rekentijd nodig hebben als tijdens de opbouw van het vorige model.

\npar Als we zo een aantal keer het herkenningssysteem willen uitbreiden zullen we veel kostbare tijd en energie verspillen.

\begin{figure}[!t]
	\centering
	\def\svgscale{0.8}
	\input{figuren/one-shot-analogie.pdf_tex}
	\caption{Een persoon die nog nooit een hoverboard heeft gezien kan gemakkelijk na het zien van de rode hoverboard, de andere uit de reeks gelijkaardige objecten halen. }\label{fig:one-shot-analogie}
\end{figure}

\subsection{Leren uit \'e\'en voorbeeld}
Mensen kunnen heel makkelijk en snel visuele concepten leren herkennen vanuit slechts een voorbeeld. Hoe de mens dit precies doet is iets waar de wetenschap het nog niet compleet over eens is.

\npar \cite{recognition-components} bespreekt de ``Recognition by components'' theorie  die deze kwaliteit kan verklaren. Als de mens een nieuw object voor het eerst ziet, zal hij deze trachten op te delen in verschillende onderdelen die hij herkent. Stel dat iemand voor het eerst in zijn leven een hoverboard ziet (zie Figuur \ref{fig:one-shot-analogie}) dan kan hij deze na een bezichtiging snel differenti\"eren. We herkennen vormen uit andere objecten die we al kennen en vanuit deze informatie maken we een representatie van het nieuwe object. Als je die persoon achteraf zou vragen het object te beschrijven, kan hij bijvoorbeeld zeggen dat het eruitziet als een segway met kleine wielen en geen stuur of op een lager niveau een plank met twee wielen horizontaal naast elkaar.

\npar In deze gedachtengang zouden we een reeds getraind herkenningsmodel, dat net zoals de mens bepaalde vormen, lijnen, handposities, houdingen of armbewegingen kan detecteren, een nieuw gebaar kunnen bijleren. De voorwaarde is dat het model de algemene kenmerken van een gebaar herkent, zodat deze ook voor de herkenning van een nieuw gebaar kunnen gebruikt worden. Op deze manier kan er geprobeerd worden om uit slechts \'e\'en voorbeeld bij te leren. Dit is de essentie van one-shot learning. 

\subsection{One-shot learning in de literatuur}
\npar \cite{oneshot-vis-concepts} stelt een generatief model voor voor het herkennen van handgeschreven karakters. Het vertrekt vanuit de notie dat de mens een teken schrijft in verschillende halen of lijnen en ook zo een nieuw teken leert herkennen. Er wordt een dataset opgebouwd van 1600 karakters die door verschillende gebruikers online geregistreerd worden. Elke lijn die een gebruiker plaatst wordt opgeslaan alsook de volgorde van tekenen. Zo bestaat elk teken uit een opeenvolging van lijnen met verschillende vorm en lengte. De verzameling van al deze lijnen wordt gebruikt als voorafgaande kennis om nieuwe tekens bij te leren met een voorbeeld. Het nieuwe teken wordt door het systeem opgedeeld in lijncomponenten die dan afgetoetst worden tegen het model. Zo ontstaat een nieuwe representatie voor het bijgeleerde gebaar die kan gebruikt worden voor herkenning. Er wordt een nauwkeurigheid van 54.9 \% behaald tegenover 39.6 \% voor een implementatie aan de hand van Deep Boltzman Machines (DBM). Wanneer bij het aanleren van het nieuwe gebaar de lijninformatie van de dataset wordt gebruikt in plaats van die van het systeem zelf wordt een nauwkeurigheid van 63.7 \% waargenomen.

\npar \cite{oneshot-gesture-rgbd} buigt zich over de ChaLearn One-shot Learning Gesture Challenge 2011 en leert vanuit slechts een voorbeeld een gebaar te herkennen zonder enige voorgaande kennis. Er wordt ge\"experimenteerd met een aantal feature descriptors en classificatie methodes waaruit Extended Motion History Images (Extended MHI) en Maximum Correlation Co\"effici\"ent (MCC) als best presterende worden gevonden. Extended MHI  bestaat zelf uit drie representaties: MHI en Inversed recording (INV) focussen zich op bewegingsinformatie respectievelijk in het begin en op het einde van het gebaar terwijl Gait Energy Information (GEI) repetitieve beweging registreert. Het systeem behaalt een Levensteihnafstand van 0.29685 (tussen 0 en 1 waarbij 0 optimaal) op de validatieset en presteert zeer goed op gebaren waarin er veel beweging is. De twee meer statische gebaren uit de dataset worden het minst goed gededecteerd met een nauwkeurigheid lager dan 45 \%.

\npar \cite{oneshot-video-segm} stelt een convolutioneel neuraal netwerk (CNN) voor die uit een voorbeeld de voorgrond van de achtergrond onderscheidt in een video. Het CNN wordt vooraf getraind op de ImageNet dataset. Een dataset van 1,2 miljoen afbeeldingen uit meer dan duizend categori\"en. Door deze pre-training op een zeer ruime dataset is het model algemeen en leert het eigenlijk wat 'een object' is. Hierna wordt het model verfijnd voor het volgen van een voorgrondsobject uit een video. Het eerste frame van de video wordt gemaskeerd en hierop stelt het model zich af. Deze architectuur verbetert de state-of-the-art op de Densely Annotated Video Segmentation (DAVIS) dataset met 11.2 \% (79.8\% vs 68.0\%).

\section{Doelstelling}
Dit onderzoek test de uitbreidbaarheid van een gebarenherkenningssysteem met als uiteindelijk doel het bijleren van een gebaar uit \'e\'en voorbeeld.
\npar Deze masterproef bouwt verder op het werk van \cite{lionel} die een convolutioneel neuraal netwerk (CNN) opstelde voor de herkenning van 20 Italiaanse gebaren uit de ``ChaLearn Looking at People 2014 Challenge'' dataset. Een CNN is een model uit de deep learning, een aftakking van machine learning en behaalt state-of-the-art op foto-, video- en actieclassificatie.  Hij behaalde een classificatiefout van 4.32 \%, goed voor een vijfde plaats op deze wedstrijd. Hier zal een gelijkaardig CNN worden opgesteld waarmee dan experimenten rond bijleren zullen worden uitgevoerd.
\npar Een CNN leert automatisch vanuit data algemene kenmerken te extraheren om een specifieke taak uit te voeren. Voorwaarde is dat er genoeg data voor handen is. Hier zal nagegaan worden of deze kennis effici\"ent gebruikt kan worden om met weinig voorbeelden een gebaar bij te leren en zo het herkenbare lexicon te vergroten. Er wordt vertrokken vanuit een model getraind op een grote verzameling gebarenvoorbeelden. Dan wordt het model gehertraind op de herkenning van het nieuwe gebaar. Hierbij zal het zijn reeds verworven kennis over gebaren moeten gebruiken. Voor dit bijleren mag het niet de bedoeling zijn om het volledige model te hertrainen.

\npar  Het uiteindelijke doel is one-shot learning: met slechts een gebaar als voorbeeld een nieuw gebaar leren herkennen.  Omdat deze taak erg uitdagend is zal er ook worden nagegaan of we met een weinig aantal voorbeelden het lexicon kunnen uitbreiden. Zo kan er bepaald worden vanaf hoeveel voorbeelden het model goed presteert en kan dit opgenomen worden als uitbreidingsvoorwaarde van bijvoorbeeld een online platform waarop gebruikers datavoorbeelden kunnen insturen.

\npar Er zal ook worden nagegaan of het model meerdere keren kan uitgebreid worden en hoe dit het best gebeurt. Het bijleren van een gebaar lijkt haalbaar, maar indien we meerdere gebaren na elkaar bijleren moet het model nog altijd even goed presteren. Er mag zeker en vast geen functionaliteit verloren gaan. Concreet wil dit zeggen dat als er een nieuw gebaar wordt bijgeleerd, dit niet de herkenning van de reeds aangeleerde gebaren mag verstoren. Het model mag dus niet volledig hertraind worden. Niet alleen omdat dan kennis kan verloren gaan, maar ook omdat dit veel tijd zal kosten. Een diep neuraal netwerk bestaat uit verschillende lagen. Hoe minder lagen we hertrainen hoe minder rekenwerk er moet verricht worden.

\npar Omdat er met weinig voorbeelden gewerkt wordt, lijkt het een goed idee om artifici\"ele data te cre\"eren. Dit gebeurt aan de hand van data-augmentatie: beelden worden licht getransformeerd om meerdere vari\"erende beelden uit een echt voorbeeld te krijgen.

\npar Samengevat zal dit onderzoek trachten een gebaar bij te leren aan een CNN en hierbij het volgende onderzoeken:
\begin{itemize}
	\item invloed van aantal gebruikte voorbeelden en vanaf hoeveel voorbeelden er aanvaardbare resultaten bekomen worden,
	\item invloed van aantal hertrainde lagen op het herkenningsvermogen van het nieuwe gebaar,
	\item invloed van verschillende data-augmentatie technieken,
	\item de dynamisch uitbreidbaarheid van het systeem: kunnen we gebaren blijven toevoegen zonder verlies van prestatie.
\end{itemize}






 